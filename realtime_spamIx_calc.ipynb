{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <<뉴럴넷 실시간 스팸지수 계산기>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ktai21\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter 설정\n",
    "* 디렉토리 위치\n",
    "* 뉴럴넷 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realtime_spam_calc 디렉토리가 있는 경로 지정\n",
    "MAIN_DIR = 'C:/Users/ktai21/Documents/hoho/script/realtime_spam_calc/'\n",
    "DATA_NAME = 'fake_CDR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#현재 경로 설정\n",
    "os.chdir(MAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Raw CDR Data Onehot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전화번호 유형 onehot encoding 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phone_number_type\n",
    "def number_type_onehot(df_local):\n",
    "    type_list = pd.read_excel('./data/reference_data/phone_number_type.xlsx', dtype='object')\n",
    "\n",
    "    type_list.ix[0]['번호'] = '100' # 특정 row가 string이 아닌, int로 들어감. string으로 들어가도록 전처리.\n",
    "    type_list.ix[160]['번호'] = '1522' # 특정 row가 string이 아닌, int로 들어감. string으로 들어가도록 전처리.\n",
    "\n",
    "    type_list['자리수'] = 0\n",
    "    for i in range(len(type_list)):\n",
    "        type_list['자리수'][i] = len(type_list['번호'][i])\n",
    "\n",
    "    df_0 = type_list[type_list['타입 번호']=='0']\n",
    "    df_0_2 = df_0[df_0['자리수']==2]\n",
    "    df_0_3 = df_0[df_0['자리수']==3]\n",
    "    df_0_4 = df_0[df_0['자리수']==4]\n",
    "    df_0_5 = df_0[df_0['자리수']==5]\n",
    "    df_0_2_list = np.array(df_0[df_0['자리수']==2])\n",
    "    df_0_3_list = np.array(df_0[df_0['자리수']==3])\n",
    "    df_0_4_list = np.array(df_0[df_0['자리수']==4])\n",
    "    df_0_5_list = np.array(df_0[df_0['자리수']==5])\n",
    "\n",
    "\n",
    "    df_1 = type_list[type_list['타입 번호']=='1']\n",
    "    df_1_2 = df_1[df_1['자리수']==2]\n",
    "    df_1_3 = df_1[df_1['자리수']==3]\n",
    "    df_1_4 = df_1[df_1['자리수']==4]\n",
    "    df_1_5 = df_1[df_1['자리수']==5]\n",
    "    df_1_2_list = np.array(df_1[df_1['자리수']==2])\n",
    "    df_1_3_list = np.array(df_1[df_1['자리수']==3])\n",
    "    df_1_4_list = np.array(df_1[df_1['자리수']==4])\n",
    "    df_1_5_list = np.array(df_1[df_1['자리수']==5])\n",
    "\n",
    "    df_2 = type_list[type_list['타입 번호']=='2']\n",
    "    df_2_2 = df_2[df_2['자리수']==2]\n",
    "    df_2_3 = df_2[df_2['자리수']==3]\n",
    "    df_2_4 = df_2[df_2['자리수']==4]\n",
    "    df_2_5 = df_2[df_2['자리수']==5]\n",
    "    df_2_2_list = np.array(df_2[df_2['자리수']==2])\n",
    "    df_2_3_list = np.array(df_2[df_2['자리수']==3])\n",
    "    df_2_4_list = np.array(df_2[df_2['자리수']==4])\n",
    "    df_2_5_list = np.array(df_2[df_2['자리수']==5])\n",
    "\n",
    "    df_3 = type_list[type_list['타입 번호']=='3']\n",
    "    df_3_2 = df_3[df_3['자리수']==2]\n",
    "    df_3_3 = df_3[df_3['자리수']==3]\n",
    "    df_3_4 = df_3[df_3['자리수']==4]\n",
    "    df_3_5 = df_3[df_3['자리수']==5]\n",
    "    df_3_2_list = np.array(df_3[df_3['자리수']==2])\n",
    "    df_3_3_list = np.array(df_3[df_3['자리수']==3])\n",
    "    df_3_4_list = np.array(df_3[df_3['자리수']==4])\n",
    "    df_3_5_list = np.array(df_3[df_3['자리수']==5])\n",
    "\n",
    "    df_4 = type_list[type_list['타입 번호']=='4']\n",
    "    df_4_2 = df_4[df_4['자리수']==2]\n",
    "    df_4_3 = df_4[df_4['자리수']==3]\n",
    "    df_4_4 = df_4[df_4['자리수']==4]\n",
    "    df_4_5 = df_4[df_4['자리수']==5]\n",
    "    df_4_2_list = np.array(df_4[df_4['자리수']==2])\n",
    "    df_4_3_list = np.array(df_4[df_4['자리수']==3])\n",
    "    df_4_4_list = np.array(df_4[df_4['자리수']==4])\n",
    "    df_4_5_list = np.array(df_4[df_4['자리수']==5])\n",
    "    df_4_6_list = np.array(df_4[df_4['자리수']==6])\n",
    "\n",
    "    df_5 = type_list[type_list['타입 번호']=='5']\n",
    "    df_5_2 = df_5[df_5['자리수']==2]\n",
    "    df_5_3 = df_5[df_5['자리수']==3]\n",
    "    df_5_4 = df_5[df_5['자리수']==4]\n",
    "    df_5_5 = df_5[df_5['자리수']==5]\n",
    "    df_5_2_list = np.array(df_5[df_5['자리수']==2])\n",
    "    df_5_3_list = np.array(df_5[df_5['자리수']==3])\n",
    "    df_5_4_list = np.array(df_5[df_5['자리수']==4])\n",
    "    df_5_5_list = np.array(df_5[df_5['자리수']==5])\n",
    "\n",
    "    df_6 = type_list[type_list['타입 번호']=='6']\n",
    "    df_6_2 = df_6[df_6['자리수']==2]\n",
    "    df_6_3 = df_6[df_6['자리수']==3]\n",
    "    df_6_4 = df_6[df_6['자리수']==4]\n",
    "    df_6_5 = df_6[df_6['자리수']==5]\n",
    "    df_6_2_list = np.array(df_6[df_6['자리수']==2])\n",
    "    df_6_3_list = np.array(df_6[df_6['자리수']==3])\n",
    "    df_6_4_list = np.array(df_6[df_6['자리수']==4])\n",
    "    df_6_5_list = np.array(df_6[df_6['자리수']==5])\n",
    "\n",
    "    df_7 = type_list[type_list['타입 번호']=='7']\n",
    "    df_7_2 = df_7[df_7['자리수']==2]\n",
    "    df_7_3 = df_7[df_7['자리수']==3]\n",
    "    df_7_4 = df_7[df_7['자리수']==4]\n",
    "    df_7_5 = df_7[df_7['자리수']==5]\n",
    "    df_7_2_list = np.array(df_7[df_7['자리수']==2])\n",
    "    df_7_3_list = np.array(df_7[df_7['자리수']==3])\n",
    "    df_7_4_list = np.array(df_7[df_7['자리수']==4])\n",
    "    df_7_5_list = np.array(df_7[df_7['자리수']==5])\n",
    "\n",
    "\n",
    "    df_test = df_local\n",
    "\n",
    "    #setting columns\n",
    "    df_test[\"SCH_PH_type\"]=8\n",
    "    df_test[\"SCH_PH_new\"]=df_test[\"SCH_PH\"]\n",
    "    cols = df_test.columns.tolist()\n",
    "    cols_new = cols[-2:] + [cols[0]]\n",
    "    df_test = df_test[cols_new]\n",
    "    #df_test.reset_index(inplace=True) #index column을 0열에 추가해준다.\n",
    "\n",
    "    df_test[['SCH_PH_type']].astype(int)\n",
    "\n",
    "    df_test.reset_index(inplace=True) #index column을 0열에 추가해준다.\n",
    "\n",
    "    #from dask to np.array\n",
    "    df_test = np.array(df_test)\n",
    "\n",
    "    # from int to string\n",
    "    for i in range(len(df_test)):\n",
    "        if type(df_test[i][2]) == int:\n",
    "            df_test[i][2] = str(df_test[i][2])\n",
    "        elif type(df_test[i][2]) == float:\n",
    "            df_test[i][2] = str(df_test[i][2])\n",
    "\n",
    "    #\"+82\" 전처리\n",
    "    for i in range(len(df_test)):\n",
    "        x1 = df_test[i][2][:3]\n",
    "        if x1 == '+82':\n",
    "            x2 = df_test[i][2]\n",
    "            x3 = df_test[i][2][3:]\n",
    "            if len(x2)==13:\n",
    "                df_test[i][2] = '0'+ x3\n",
    "            if len(x2)==11:\n",
    "                df_test[i][2] = x3\n",
    "\n",
    "    #\"*23#\" 전처리\n",
    "    for i in range(len(df_test)):\n",
    "        x4 = df_test[i][2][:4]\n",
    "        if x4 =='*23#':\n",
    "            df_test[i][2] = df_test[i][2][4:]\n",
    "\n",
    "    # processing\n",
    "    for i in range(len(df_test)):\n",
    "        x0 = df_test[i][2][:6]\n",
    "        if x0 in df_4_6_list:\n",
    "            df_test[i][1] = 4\n",
    "        else:\n",
    "            pass\n",
    "    df_test_6_N = df_test[df_test[:, 1]==8]\n",
    "    df_test_6_Y = df_test[df_test[:, 1]!=8]    \n",
    "\n",
    "    df_test = df_test_6_N\n",
    "    for i in range(len(df_test)):\n",
    "        x5 = df_test[i][2][:5]\n",
    "        if x5 in df_0_5_list:\n",
    "            df_test[i][1] = 0\n",
    "        elif x5 in df_1_5_list:\n",
    "            df_test[i][1] = 1\n",
    "        elif x5 in df_5_5_list:\n",
    "            df_test[i][1] = 5\n",
    "        elif x5 in df_7_5_list:\n",
    "            df_test[i][1] = 7\n",
    "        else:\n",
    "            pass\n",
    "    df_test_5_N = df_test[df_test[:, 1]==8]\n",
    "    df_test_5_Y = df_test[df_test[:, 1]!=8]\n",
    "\n",
    "    df_test = df_test_5_N\n",
    "    for i in range(len(df_test)):\n",
    "        x6 = df_test[i][2][:4]\n",
    "        if x6 in df_4_4_list:\n",
    "            df_test[i][1] = 4\n",
    "        elif x6 in df_6_4_list:\n",
    "            df_test[i][1] = 6\n",
    "        elif x6 in df_7_4_list:\n",
    "            df_test[i][1] = 7\n",
    "        elif x6 in df_1_4_list:\n",
    "            df_test[i][1] = 1\n",
    "        else:\n",
    "            pass\n",
    "    df_test_4_N = df_test[df_test[:, 1]==8]\n",
    "    df_test_4_Y = df_test[df_test[:, 1]!=8]\n",
    "\n",
    "    df_test = df_test_4_N\n",
    "    for i in range(len(df_test)):\n",
    "        x7 = df_test[i][2][:3]\n",
    "        if x7 in df_4_3_list:\n",
    "            df_test[i][1] = 4\n",
    "        elif x7 in df_3_3_list:\n",
    "            df_test[i][1] = 3\n",
    "        elif x7 in df_1_3_list:\n",
    "            df_test[i][1] = 1\n",
    "        elif x7 in df_0_3_list:\n",
    "            df_test[i][1] = 0\n",
    "        elif x7 in df_2_3_list:\n",
    "            df_test[i][1] = 2\n",
    "        elif x7 in df_5_3_list:\n",
    "            df_test[i][1] = 5\n",
    "        else:\n",
    "            pass\n",
    "    df_test_3_N = df_test[df_test[:, 1]==8]\n",
    "    df_test_3_Y = df_test[df_test[:, 1]!=8]\n",
    "\n",
    "    df_test = df_test_3_N\n",
    "    for i in range(len(df_test)):\n",
    "        if df_test[i][2][:2] in df_3_2_list:\n",
    "            df_test[i][1] = 3\n",
    "        else:\n",
    "            pass\n",
    "    df_test_2_N = df_test[df_test[:, 1]==8]\n",
    "    df_test_2_Y = df_test[df_test[:, 1]!=8]\n",
    "\n",
    "    result_mat = np.concatenate((df_test_6_Y, df_test_5_Y, df_test_4_Y, df_test_3_Y, df_test_2_Y, df_test_2_N)) #np.array concatenate\n",
    "    result_mat2 = pd.DataFrame(result_mat) #np.array -> pd.DataFrame\n",
    "    result_mat3 = result_mat2.sort_values(0) #sorting by index\n",
    "    result_mat4 = result_mat3[[1, 2, 3]] #deleting the ndex column\n",
    "    result_mat5 = np.array(result_mat4) #pd.DataFrame -> np.array\n",
    "\n",
    "    df_test2 = pd.DataFrame(result_mat5)\n",
    "    mat = np.array(df_test2[[0]])\n",
    "    mat2 = mat.reshape(-1, 1)\n",
    "\n",
    "    enc.fit(X=mat2)\n",
    "    #enc.n_values_\n",
    "    #enc.feature_indices_\n",
    "    mat3 = enc.transform(mat2).toarray()\n",
    "    mat4 = np.array(mat3, dtype=int)\n",
    "\n",
    "    result = pd.DataFrame(mat4)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전화번호 유형 외 Onehot Encoding 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주소록에 있다면 1\n",
    "def ADDRBOOK_FLAG_Y_checker(value):\n",
    "    if value == 'Y':\n",
    "        return 1\n",
    "    elif value == 'N':\n",
    "        return 0\n",
    "\n",
    "# 주소록에 없으면 1\n",
    "def ADDRBOOK_FLAG_N_checker(value):\n",
    "    if value == 'N':\n",
    "        return 1\n",
    "    elif value == 'Y':\n",
    "        return 0\n",
    "    \n",
    "def SPAM_CD_checker(value, criteria):\n",
    "    if value== criteria:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Month\n",
    "def holiday_checker_4month(dt):    \n",
    "    day = int(dt.split(' ')[0].split('-')[2])    \n",
    "    if day in [1,7,8,14,15,21,22,28,29]:\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def weekday_checker_4month(dt):    \n",
    "    day = int(dt.split(' ')[0].split('-')[2])    \n",
    "    if day in [1,7,8,14,15,21,22,28,29]:\n",
    "        return 0\n",
    "    else :\n",
    "        return 1\n",
    "\n",
    "def holiday_checker_5month(dt):    \n",
    "    day = int(dt.split(' ')[0].split('-')[2])    \n",
    "    if day in [5,6,7,12,13,19,20,22,26,27]:\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def weekday_checker_5month(dt):    \n",
    "    day = int(dt.split(' ')[0].split('-')[2])    \n",
    "    if day in [5,6,7,12,13,19,20,22,26,27]:\n",
    "        return 0\n",
    "    else :\n",
    "        return 1\n",
    "\n",
    "def holiday_checker_6month(dt):    \n",
    "    day = int(dt.split(' ')[0].split('-')[2])    \n",
    "    if day in [2,3,6,9,10,16,17,23,24,30]:\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def weekday_checker_6month(dt):    \n",
    "    day = int(dt.split(' ')[0].split('-')[2])    \n",
    "    if day in [2,3,6,9,10,16,17,23,24,30]:\n",
    "        return 0\n",
    "    else :\n",
    "        return 1\n",
    "    \n",
    "# Hour 원핫 인코딩\n",
    " # group-3\n",
    "def hour0_checker(dt): \n",
    "    hour = int(dt.split(' ')[-1].split(':')[0])\n",
    "    if hour in [0,1,2,3,4,5,6,7,8,18,19,20,21,22,23]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def hour1_checker(dt):\n",
    "    hour = int(dt.split(' ')[-1].split(':')[0])    \n",
    "    if hour in [9,10]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def hour2_checker(dt):\n",
    "    hour = int(dt.split(' ')[-1].split(':')[0])\n",
    "    if hour in [11,12]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def hour3_checker(dt):    \n",
    "    hour = int(dt.split(' ')[-1].split(':')[0])\n",
    "    if hour in [13,14,15,16,17]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def pub_nm_checker_Y(dt):\n",
    "    if dt != '0':\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def pub_nm_checker_N(dt):\n",
    "    if dt == '0':\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def call_type_checker_P(calltype):    \n",
    "    if calltype == 'P':\n",
    "        return 1\n",
    "    elif calltype =='M':\n",
    "        return 0\n",
    "    \n",
    "def call_type_checker_M(calltype):    \n",
    "    if calltype == 'M':\n",
    "        return 1\n",
    "    elif calltype =='P':\n",
    "        return 0\n",
    "    \n",
    "spam_cd_list = ['0', 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 98.0, 99.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw CDR Data Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ktai21\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n",
      "C:\\Users\\ktai21\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "C:\\Users\\ktai21\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===6.244726181030273 seconds===\n"
     ]
    }
   ],
   "source": [
    "def encoder():\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    #저장할 df 생성\n",
    "    df_onehot = pd.DataFrame()\n",
    "\n",
    "    df = pd.read_csv('./data/original_data/{}.csv'.format(DATA_NAME))\n",
    "    ###############################################\n",
    "    \n",
    "    df_num_onehot = number_type_onehot(df)\n",
    "    df_onehot = df_num_onehot\n",
    "    \n",
    "    \n",
    "    df['PUB_NM'] = df['PUB_NM'].fillna('0')\n",
    "    df_onehot['PUB_NM_Y'] = df['PUB_NM'].apply(pub_nm_checker_Y)\n",
    "    df_onehot['PUB_NM_N'] = df['PUB_NM'].apply(pub_nm_checker_N)\n",
    "\n",
    "    df_onehot['weekday'] = df['ACCESS_DT'].apply(weekday_checker_4month)\n",
    "    df_onehot['weekend'] = df['ACCESS_DT'].apply(holiday_checker_4month)\n",
    "\n",
    "    df_onehot['hour_0'] = df['ACCESS_DT'].apply(hour0_checker)\n",
    "    df_onehot['hour_1'] = df['ACCESS_DT'].apply(hour1_checker)\n",
    "    df_onehot['hour_2'] = df['ACCESS_DT'].apply(hour2_checker)\n",
    "    df_onehot['hour_3'] = df['ACCESS_DT'].apply(hour3_checker)\n",
    "\n",
    "    df_onehot['CALL_TYPE_P'] = df['CALL_TYPE'].apply(call_type_checker_P)\n",
    "    df_onehot['CALL_TYPE_M'] = df['CALL_TYPE'].apply(call_type_checker_M)\n",
    "\n",
    "\n",
    "    ###############################################\n",
    "    df_onehot['ADDRBOOK_FLAG_Y'] = df['ADDRBOOK_FLAG'].apply(ADDRBOOK_FLAG_Y_checker)\n",
    "    df_onehot['ADDRBOOK_FLAG_N'] = df['ADDRBOOK_FLAG'].apply(ADDRBOOK_FLAG_N_checker)\n",
    "\n",
    "    # NaN 은 0으로 바꿔준뒤\n",
    "    df['SPAM_CD'] = df['SPAM_CD'].fillna('0')    \n",
    "    for c in spam_cd_list:\n",
    "        df_onehot['SPAM_CD_{}'.format(str(int(c)))] = df['SPAM_CD'].apply(SPAM_CD_checker, criteria = c)\n",
    "\n",
    "\n",
    "    # 새 디렉토리에 이름 바꿔서 저장 \n",
    "    df_onehot.to_csv('./data/onehot_data/{}_onehot.csv'.format(DATA_NAME), index=False)\n",
    "    print(\"===%s seconds===\"% (time.time() - start_time))\n",
    "    \n",
    "encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Deep Learning Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(object):\n",
    "    def __init__(self, sess, units=1000, name=None, threshold= 0.5):\n",
    "        self.sess = sess\n",
    "        self.units = units\n",
    "        self.name = name\n",
    "        self.threshold = threshold\n",
    "        self._build_net()\n",
    "        print(self.name)\n",
    "        \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            self.X = tf.placeholder(tf.float32, shape=[None, 37])\n",
    "            self.Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "            self.learning_rate = tf.placeholder(tf.float32)\n",
    "            \n",
    "            L1 = tf.layers.dense(self.X, units=self.units, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer(), name='L1')\n",
    "            L1 = tf.layers.batch_normalization(L1, training=self.training, name='batchnorm1')\n",
    "            #L1 = tf.nn.relu(L1, name='relu1')\n",
    "            L1 = tf.sigmoid(L1, name='sigmoid1')\n",
    "            L1 = tf.layers.dropout(L1, rate=0.7, training=self.training, name='dropout1')\n",
    "            L2 = tf.layers.dense(L1, units=self.units, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer(), name='L2')\n",
    "            L2 = tf.layers.batch_normalization(L2, training=self.training, name='batchnorm2')\n",
    "            #L2 = tf.nn.relu(L2, name='relu2')\n",
    "            L2 = tf.sigmoid(L2, name='sigmoid2')\n",
    "            L2 = tf.layers.dropout(L2, rate=0.7, training=self.training, name='dropout2')\n",
    "            self.logits = tf.layers.dense(L2, units=1, activation=tf.sigmoid, kernel_initializer=tf.contrib.layers.xavier_initializer(), name='logits')\n",
    "        \n",
    "        #self.cost = tf.reduce_mean(tf.square(self.logits - self.Y))\n",
    "        #self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.Y))\n",
    "        # softmax는 multinomial classification\n",
    "        self.cost = -tf.reduce_mean(self.Y * tf.log(self.logits) + (1-self.Y) * tf.log(1-self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n",
    "        self.predicted = tf.cast(self.logits > self.threshold, dtype=tf.float32)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(self.predicted, self.Y), dtype=tf.float32))\n",
    "        \n",
    "    def predict(self, test_X, test_Y, training=False):\n",
    "        return self.sess.run([self.logits, self.predicted], feed_dict={self.X: test_X, self.Y: test_Y, self.training: training})\n",
    "    \n",
    "    def train(self, train_X, train_Y, learning_rate, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.X: train_X, self.Y: train_Y, self.learning_rate: learning_rate, self.training: training})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 100\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.9\n",
    "batch_size = 10000\n",
    "\n",
    "units = 1024\n",
    "learning_rate = 0.0001\n",
    "threshold = 0.756"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer2_lr0.0001_node1024\n"
     ]
    }
   ],
   "source": [
    "model_name = 'layer2_lr{}_node{}'.format(learning_rate, units)\n",
    "\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "model = NN(sess=sess, name=model_name, units=units, threshold = threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/20180623_0_result.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "latest_checkpoint = '20180623_0_result.ckpt'\n",
    "\n",
    "saver = tf.train.import_meta_graph('./checkpoint/{}.meta'.format(latest_checkpoint))\n",
    "saver.restore(sess,'./checkpoint/{}'.format(latest_checkpoint))\n",
    "#tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스팸지수 예측(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/onehot_data/fake_CDR_onehot.csv START!\n",
      "./data/onehot_data/fake_CDR_onehot.csv Load COMPLETE!\n",
      "[0.]\n",
      "./data/onehot_data/fake_CDR_onehot.csv COMPLETE!\t0.21941351890563965s\n"
     ]
    }
   ],
   "source": [
    "#data 위치\n",
    "TEST_DATA= './data/onehot_data/{}_onehot.csv'.format(DATA_NAME)\n",
    "\n",
    "with tf.device('/gpu:0'):     \n",
    "    start = time.time()\n",
    "    print(TEST_DATA, 'START!')\n",
    "    data = np.loadtxt(TEST_DATA, dtype=np.int, delimiter=',', skiprows=1)\n",
    "    print(TEST_DATA, 'Load COMPLETE!')\n",
    "    x_data = data[:,:37]\n",
    "    y_data = data[:,-1].reshape(-1,1)\n",
    "    logit, pred = model.predict(x_data, y_data)\n",
    "    data = np.concatenate((data[:,:-1], pred), axis=1)\n",
    "    print(sum(pred))\n",
    "    np.savetxt(TEST_DATA, data, fmt='%d', delimiter=',')\n",
    "    print(TEST_DATA, 'COMPLETE!\\t{}s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비식별 발신번호에 대한 스팸 지수 예측 결과 보여주기\n",
    "* (정상, 관심, 주의, 경계, 심각)의 범주로 보여주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(df_number, logit):\n",
    "    for idx in range(df_number.shape[0]):\n",
    "        original_num = df_number['SCH_PH'][idx]\n",
    "        prediction = logit[idx]        \n",
    "        criteria = max(logit)[0] - (max(logit)[0] - min(logit)[0])/2\n",
    "        \n",
    "        print('============prediction result=============')\n",
    "        if criteria <= logit[idx]:\n",
    "            print(original_num, ' 는 경계번호일 가능성이 있습니다.')\n",
    "        else :\n",
    "            print(original_num, ' 는 주의번호일 가능성이 있습니다.')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============prediction result=============\n",
      "*23#01012345678  는 주의번호일 가능성이 있습니다.\n",
      "============prediction result=============\n",
      "15881234  는 경계번호일 가능성이 있습니다.\n",
      "============prediction result=============\n",
      "07012345678  는 주의번호일 가능성이 있습니다.\n",
      "============prediction result=============\n",
      "+8215441234  는 경계번호일 가능성이 있습니다.\n",
      "============prediction result=============\n",
      "021234567  는 주의번호일 가능성이 있습니다.\n",
      "============prediction result=============\n",
      "0311234567  는 주의번호일 가능성이 있습니다.\n",
      "============prediction result=============\n",
      "+821012345678  는 주의번호일 가능성이 있습니다.\n",
      "============prediction result=============\n",
      "112  는 주의번호일 가능성이 있습니다.\n",
      "============prediction result=============\n",
      "08213546543  는 주의번호일 가능성이 있습니다.\n",
      "============prediction result=============\n",
      "1541  는 주의번호일 가능성이 있습니다.\n",
      "============prediction result=============\n",
      "99999999  는 주의번호일 가능성이 있습니다.\n",
      "============prediction result=============\n",
      "00370312154  는 주의번호일 가능성이 있습니다.\n"
     ]
    }
   ],
   "source": [
    "df_number = pd.read_csv('./data/original_data/{}.csv'.format(DATA_NAME), usecols=['SCH_PH'])\n",
    "post_process(df_number, logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
